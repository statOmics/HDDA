<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Adapted by Milan Malfait and Leo Fuhrhop" />


<title>Lab 4: Sparse PCA and LDA</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #204a87; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #204a87; font-weight: bold; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

.sourceCode .row {
  width: 100%;
}
.sourceCode {
  overflow-x: auto;
}
.code-folding-btn {
  margin-right: -30px;
}
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>


<style type="text/css">
#rmd-source-code {
  display: none;
}
</style>

<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HDDA</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-chalkboard-teacher"></span>
     
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="intro.html">1. Introduction</a>
    </li>
    <li>
      <a href="svd.html">2. Singular Value Decomposition</a>
    </li>
    <li>
      <a href="prediction.html">3. Prediction with High Dimensional Predictors</a>
    </li>
    <li>
      <a href="sparseSvd.html">4. Sparse Singular Value Decomposition</a>
    </li>
    <li>
      <a href="lda.html">5. Linear Discriminant Analysis</a>
    </li>
    <li>
      <a href="hclust.html">6.1. Introduction to Clustering</a>
    </li>
    <li>
      <a href="https://sites.stat.washington.edu/people/raftery/Research/PDF/fraley1998.pdf">6.2. Paper Model-based Clustering</a>
    </li>
    <li>
      <a href="em.html">6.3. EM algorithm</a>
    </li>
    <li>
      <a href="lsi.html">7. Large Scale Inference</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-laptop"></span>
     
    Labs
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Lab1-Intro-SVD.html">Lab 1: Intro &amp; SVD</a>
    </li>
    <li>
      <a href="Lab2-PCA.html">Lab 2: SVD - PCA</a>
    </li>
    <li>
      <a href="Lab3-Penalized-Regression.html">Lab 3: Prediction</a>
    </li>
    <li>
      <a href="Lab4-Sparse-PCA-LDA.html">Lab 4: Sparse PCA &amp; LDA</a>
    </li>
    <li>
      <a href="Lab5-Clustering.html">Lab 5: Clustering</a>
    </li>
    <li>
      <a href="Lab6-Large-Scale-Inference.html">Lab 6: LSI</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="https://github.com/statOmics/HDDA">
    <span class="fab fa-github"></span>
     
  </a>
</li>
<li>
  <a href="http://statomics.github.io/">statOmics</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Lab 4: Sparse PCA and LDA</h1>
<h3 class="subtitle">High Dimensional Data Analysis practicals</h3>
<h4 class="author">Adapted by Milan Malfait and Leo Fuhrhop</h4>
<h4 class="date">18 Nov 2021 <br/> (Last updated: 2025-11-06)</h4>

</div>


<div id="change-log" class="section level3 unnumbered">
<h3><a href="https://github.com/statOmics/HDDA/commits/master/Lab4-Sparse-PCA-LDA.Rmd">Change log</a></h3>
<hr />
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="do">## install packages with:</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># install.packages(c(&quot;glmnet&quot;, &quot;MASS&quot;, &quot;ggplot2&quot;, &quot;gridExtra&quot;, &quot;ggpubr&quot;))</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co"># if (!requireNamespace(&quot;remotes&quot;, quietly = TRUE)) {</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co">#     install.packages(&quot;remotes&quot;)</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># remotes::install_github(&quot;statOmics/HDDAData&quot;)</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="fu">library</span>(HDDAData)</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="fu">library</span>(ggpubr)</span></code></pre></div>
</div>
<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p><strong>In this lab session we will look at the following topics</strong></p>
<ul>
<li>Methods to set some of the loadings exactly to zero in a PCA</li>
<li>Use <code>glmnet()</code> to add penalties on principal component loadings</li>
<li>Use LDA to understand differences between groups in a high dimensional space</li>
</ul>
<div id="the-dataset" class="section level2 unnumbered">
<h2>The dataset</h2>
<p>In this practical session, we use the dataset by <span class="citation">Alon et al. (1999)</span> on gene
expression levels in 40 tumour and 22 normal colon tissue samples. They checked
a total of 6500 human genes using the Affymetrix oligonucleotide array.</p>
<p>You can load the data in as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Alon1999&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">str</span>(Alon1999[, <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>])</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co">#&gt; &#39;data.frame&#39;:    62 obs. of  10 variables:</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co">#&gt;  $ Y : chr  &quot;t&quot; &quot;n&quot; &quot;t&quot; &quot;n&quot; ...</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">#&gt;  $ X1: num  8589 9164 3826 6246 3230 ...</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co">#&gt;  $ X2: num  5468 6720 6970 7824 3694 ...</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co">#&gt;  $ X3: num  4263 4883 5370 5956 3401 ...</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co">#&gt;  $ X4: num  4065 3718 4706 3976 3464 ...</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co">#&gt;  $ X5: num  1998 2015 1167 2003 2181 ...</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co">#&gt;  $ X6: num  5282 5570 1572 2131 2923 ...</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co">#&gt;  $ X7: num  2170 3849 1325 1531 2069 ...</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="co">#&gt;  $ X8: num  2773 2793 1472 1715 2949 ...</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="co">#&gt;  $ X9: num  7526 7018 3297 3870 3303 ...</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="fu">dim</span>(Alon1999)</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="co">#&gt; [1]   62 2001</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="fu">table</span>(Alon1999<span class="sc">$</span>Y)</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a><span class="co">#&gt;  n  t </span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="co">#&gt; 22 40</span></span></code></pre></div>
<p>The dataset contains one variable named <code>Y</code> with the values <code>t</code> and <code>n</code>. This
variable indicates whether the sample came from tumourous (<code>t</code>) or normal (<code>n</code>)
tissue. For more information on this dataset, see <code>?Alon1999</code>.</p>
<p>The goal of this practical is to find the best subset / combination of genes to detect tumourous tissue.
As in <span class="citation">Alon et al. (1999)</span>, we use the 2000 genes with the highest minimal intensity
across the samples.</p>
</div>
</div>
<div id="sparse-pca" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Sparse PCA</h1>
<p>Begin by constructing the data matrix <code>X</code>, which contains the centered and scaled predictors,
and the response variable <code>Y</code> as a binary factor.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">scale</span>(Alon1999[, <span class="sc">-</span><span class="dv">1</span>], <span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(Alon1999[, <span class="dv">1</span>])</span></code></pre></div>
<p>Use these objects to solve the following exercises.</p>
<div id="tasks" class="section level2 unnumbered">
<h2>Tasks</h2>
<div id="perform-a-svd-on-x-and-store-the-scores-of-the-pcs." class="section level5 unnumbered">
<h5>1. Perform a SVD on <code>X</code> and store the scores of the PCs.</h5>
<details>
<summary>
Solution
</summary>
<p>Using <code>svd</code>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>svd_X <span class="ot">&lt;-</span> <span class="fu">svd</span>(X)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>Z <span class="ot">&lt;-</span> svd_X<span class="sc">$</span>u <span class="sc">%*%</span> <span class="fu">diag</span>(svd_X<span class="sc">$</span>d) <span class="co"># Calculate the scores</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>V <span class="ot">&lt;-</span> svd_X<span class="sc">$</span>v                 <span class="co"># Calculate the loadings</span></span></code></pre></div>
<p>Using <code>prcomp</code>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># X is already centered and scaled so no need to do again</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>pca_x <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(X, <span class="at">center =</span> <span class="cn">FALSE</span>, <span class="at">scale. =</span> <span class="cn">FALSE</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co"># The scores are given by `pca_x$x`, the loadings are `pca_x$rotation`</span></span></code></pre></div>
</details>
</div>
<div id="produce-a-scree-plot-and-confirm-that-the-first-and-second-pcs-can-approximate-the-data-to-some-extent." class="section level5 unnumbered">
<h5>2. Produce a scree plot and confirm that the first and second PCs can approximate the data to some extent.</h5>
<p>Recall from <a href="https://statomics.github.io/HDDA/Lab2-PCA.html#Tasks">Lab 2</a> that a scree plot displays the proportion of variance explained by each PC.</p>
<details>
<summary>
Solution
</summary>
<p>Calculate the proportion of variance explained by each PC.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>var_explained <span class="ot">&lt;-</span> pca_x<span class="sc">$</span>sdev<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> <span class="fu">sum</span>(pca_x<span class="sc">$</span>sdev<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co"># alternative: svd_X$d^2 / sum(svd_X$d^2)</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co"># Create dataframe for plotting</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>prop_var <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">PC =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(pca_x<span class="sc">$</span>x), <span class="at">Var =</span> var_explained)</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co"># alternative: PC = ncol(Z)</span></span></code></pre></div>
<p>Visualize with a scree plot using <code>ggplot2</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">ggplot</span>(prop_var, <span class="fu">aes</span>(PC, Var)) <span class="sc">+</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">2.5</span>, <span class="at">col =</span> <span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">60</span>, <span class="at">by =</span> <span class="dv">5</span>)) <span class="sc">+</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Proportion of variance&quot;</span>,</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Proportion of variance explained by each PC&quot;</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/pca-scree-ggplot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Alternatively, using base <code>R</code> plotting:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">plot</span>(prop_var<span class="sc">$</span>PC, prop_var<span class="sc">$</span>Var,</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;b&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Proportion of variance&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;PC&quot;</span>,</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Proportion of variance explained by each PC&quot;</span>)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">2.5</span>, <span class="at">col =</span> <span class="st">&quot;firebrick&quot;</span>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/pca-scree-plot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>About 55% of the variance in the data are explained by the first and second PCs.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">cumsum</span>(prop_var<span class="sc">$</span>Var)[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="co">#&gt;  [1] 0.4495565 0.5480190 0.6156694 0.6722213 0.7050558 0.7363469 0.7596658</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co">#&gt;  [8] 0.7818428 0.7985138 0.8140390</span></span></code></pre></div>
</details>
</div>
<div id="plot-the-first-two-pcs-and-use-different-colours-for-tumor-normal-tissue." class="section level5 unnumbered">
<h5>3. Plot the first two PCs and use different colours for tumor / normal tissue.</h5>
<p>Due to the large number of features, the biplot would be difficult to interpret. A simple scatterplot, separated by tumor / normal tissue, is more informative in this setting.</p>
<details>
<summary>
Solution
</summary>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>scores_1_2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">PC1 =</span> pca_x<span class="sc">$</span>x[, <span class="dv">1</span>], <span class="at">PC2 =</span> pca_x<span class="sc">$</span>x[, <span class="dv">2</span>], <span class="at">Tissue =</span> Y)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co"># Alternative: retrieve scores from Z[, 1], Z[, 2]</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="fu">ggplot</span>(scores_1_2, <span class="fu">aes</span>(PC1, PC2)) <span class="sc">+</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">col =</span> Tissue), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;deepskyblue2&quot;</span>, <span class="st">&quot;coral1&quot;</span>)) <span class="sc">+</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">aspect.ratio =</span> <span class="fl">0.8</span>, <span class="at">legend.position =</span> <span class="st">&quot;top&quot;</span>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/pca-tissue-ggplot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Alternatively, using base <code>R</code> plotting:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;n&quot;</span> <span class="ot">=</span> <span class="st">&quot;deepskyblue2&quot;</span>, <span class="st">&quot;t&quot;</span> <span class="ot">=</span> <span class="st">&quot;coral1&quot;</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="fu">plot</span>(scores_1_2<span class="sc">$</span>PC1, scores_1_2<span class="sc">$</span>PC2,</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>  <span class="at">col =</span> cols[Y],</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;PC1&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;PC2&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>)</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Normal&quot;</span>, <span class="st">&quot;Tumor&quot;</span>),</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>  <span class="at">col =</span> cols,</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>  <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">title =</span> <span class="st">&quot;Tissue&quot;</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/pca-tissue-plot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p><strong>Interpretation:</strong> using only the first 2 PCs does not seem to separate the tumor and normal cases clearly.</p>
</details>
</div>
<div id="plot-histograms-of-the-loadings-of-the-first-and-second-pcs.-interpret." class="section level5 unnumbered">
<h5>4. Plot histograms of the loadings of the first and second PCs. Interpret.</h5>
<details>
<summary>
Solution
</summary>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>loadings_1_2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>  <span class="at">loadings_1 =</span> pca_x<span class="sc">$</span>rotation[, <span class="dv">1</span>], <span class="at">loadings_2 =</span> pca_x<span class="sc">$</span>rotation[, <span class="dv">2</span>]</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>)</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="co"># alternative: loadings_1 = V[, 1], loadings_2 = V[, 2]</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="co"># First plot (PC1)</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(loadings_1_2, <span class="fu">aes</span>(<span class="at">x =</span> loadings_1)) <span class="sc">+</span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">50</span>, <span class="at">fill =</span> <span class="st">&quot;grey80&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>    <span class="at">xintercept =</span> <span class="fu">quantile</span>(loadings_1_2<span class="sc">$</span>loadings_1, <span class="fl">0.95</span>),</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&quot;firebrick&quot;</span>,</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>    <span class="at">linewidth =</span> <span class="fl">1.2</span></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;PC 1 loadings&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Count&quot;</span>, <span class="at">title =</span> <span class="cn">NULL</span>) <span class="sc">+</span></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a><span class="co"># Second plot (PC2)</span></span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(loadings_1_2, <span class="fu">aes</span>(<span class="at">x =</span> loadings_2)) <span class="sc">+</span></span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">50</span>, <span class="at">fill =</span> <span class="st">&quot;grey80&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a>    <span class="at">xintercept =</span> <span class="fu">quantile</span>(loadings_1_2<span class="sc">$</span>loadings_2, <span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>)),</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&quot;firebrick&quot;</span>,</span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a>    <span class="at">linewidth =</span> <span class="fl">1.2</span></span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;PC 2 loadings&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Count&quot;</span>, <span class="at">title =</span> <span class="cn">NULL</span>) <span class="sc">+</span></span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span>
<span id="cb12-27"><a href="#cb12-27" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" tabindex="-1"></a><span class="co"># Arrange plots vertically</span></span>
<span id="cb12-29"><a href="#cb12-29" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/pca-loading-ggplot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Alternatively, using base <code>R</code> plotting:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co"># First plot (PC1)</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="fu">hist</span>(loadings_1_2<span class="sc">$</span>loadings_1, <span class="at">breaks =</span> <span class="dv">50</span>, <span class="at">xlab =</span> <span class="st">&quot;PC 1 loadings&quot;</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co"># Add vertical line at 95% quantile</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">quantile</span>(loadings_1_2<span class="sc">$</span>loadings_1, <span class="fl">0.95</span>), <span class="at">col =</span> <span class="st">&quot;firebrick&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co"># Second plot (PC2)</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="fu">hist</span>(loadings_1_2<span class="sc">$</span>loadings_2, <span class="at">breaks =</span> <span class="dv">50</span>, <span class="at">xlab =</span> <span class="st">&quot;PC 2 loadings&quot;</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>  <span class="fu">quantile</span>(loadings_1_2<span class="sc">$</span>loadings_2, <span class="fl">0.05</span>),</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>  <span class="fu">quantile</span>(loadings_1_2<span class="sc">$</span>loadings_2, <span class="fl">0.95</span>)</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>), <span class="at">col =</span> <span class="st">&quot;firebrick&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/pca-loadings-plot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Vertical lines were added at the 95th percentile for PC1 and the 5th and 95th percentiles for PC2 to reflect where the largest (in absolute value) loadings are situated (no negative loadings for PC1, so only showing the 95th percentile).</p>
<p><strong>Interpretation:</strong> remember that the PC loadings reflect the <em>contributions</em> of each feature (in this case: gene) to the PC.
From these histograms it should be clear that only a minor fraction of the genes are really driving these first 2 PCs, especially for PC2 (where the bulk of genes has loadings close to 0).</p>
</details>
<p>We know that the first PC <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ùêô</mi><mn>ùüè</mn></msub><annotation encoding="application/x-tex">\mathbf{Z_1}</annotation></semantics></math> is given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ùêô</mi><mn>ùüè</mn></msub><mo>=</mo><mi>ùêó</mi><msub><mi>ùêï</mi><mn>ùüè</mn></msub><mspace width="0.167em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">
\mathbf{Z_1}=\mathbf{X} \mathbf{V_1} \, ,
</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ùêï</mi><mn>ùüè</mn></msub><annotation encoding="application/x-tex">\mathbf{V_1}</annotation></semantics></math> are the loadings of the first PC. By setting <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùõÉ</mi><mo>=</mo><msub><mi>ùêï</mi><mn>ùüè</mn></msub></mrow><annotation encoding="application/x-tex">\boldsymbol{\beta} = \mathbf{V_1}</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><msub><mi>Z</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Y = Z_1</annotation></semantics></math>, we can express this as the regression</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùêò</mi><mo>=</mo><mi>ùêó</mi><mi>ùõÉ</mi><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mathbf{Y}=\mathbf{X}\boldsymbol{\beta} \, .
</annotation></semantics></math></p>
<p>Recall that the ridge regression solution for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõÉ</mi><annotation encoding="application/x-tex">\boldsymbol{\beta}</annotation></semantics></math> is given by</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ùõÉ</mi><mtext mathvariant="normal">ridge</mtext></msub><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mrow><msup><mi>ùêó</mi><mi>ùêì</mi></msup><mi>ùêó</mi></mrow><mo>+</mo><mi>Œª</mi><mi>ùêà</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>‚àí</mi><mn>1</mn></mrow></msup><msup><mi>ùêó</mi><mi>T</mi></msup><mi>ùêò</mi><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">
\boldsymbol{\beta}_{\text{ridge}} = (\mathbf{X^TX}+\lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf Y \, .
</annotation></semantics></math></p>
</div>
<div id="replace-mathbfy-with-mathbfz_1-and-verify-numerically-in-r-that" class="section level5 unnumbered">
<h5>5. Replace <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêò</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math> with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ùêô</mi><mn>ùüè</mn></msub><annotation encoding="application/x-tex">\mathbf{Z_1}</annotation></semantics></math> and verify numerically in <code>R</code> that</h5>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ùêï</mi><mn>1</mn></msub><mo>=</mo><mfrac><msub><mi>ùõÉ</mi><mtext mathvariant="normal">ridge</mtext></msub><mrow><mo stretchy="false" form="postfix">‚à•</mo><msub><mi>ùõÉ</mi><mtext mathvariant="normal">ridge</mtext></msub><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn></msub></mrow></mfrac><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">
  \mathbf V_1 =
    \frac{\boldsymbol\beta_{\text{ridge}}}{\|\boldsymbol\beta_{\text{ridge}}\|_2} \, .
  </annotation></semantics></math></p>
<p>You may use any <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œª</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda &gt; 0</annotation></semantics></math> of your choice. Remember that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="postfix">‚à•</mo><msub><mi>ùõÉ</mi><mtext mathvariant="normal">ridge</mtext></msub><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn></msub><mo>=</mo><msqrt><mrow><msubsup><mi>ùõÉ</mi><mtext mathvariant="normal">ridge</mtext><mi>T</mi></msubsup><msub><mi>ùõÉ</mi><mtext mathvariant="normal">ridge</mtext></msub></mrow></msqrt><mo>=</mo><msqrt><mrow><msubsup><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></msubsup><msubsup><mi>Œ≤</mi><mi>j</mi><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding="application/x-tex">\|\boldsymbol\beta_{\text{ridge}}\|_2 = \sqrt{\boldsymbol\beta_{\text{ridge}}^T \boldsymbol\beta_{\text{ridge}}} = \sqrt{\sum_{j=1}^p \beta_j^2}</annotation></semantics></math>.</p>
<details>
<summary>
Solution
</summary>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>]</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>tXX_lambda_I <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> X <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">diag</span>(p)</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="co"># This might take a while to calculate</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>beta_ridge <span class="ot">&lt;-</span> <span class="fu">solve</span>(tXX_lambda_I) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> Z[, <span class="dv">1</span>]</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>mag_beta_ridge <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(beta_ridge<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(V[, <span class="dv">1</span>] <span class="sc">-</span> beta_ridge <span class="sc">/</span> mag_beta_ridge))</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="co">#&gt; [1] 2.15872e-10</span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co"># alternative for V[, 1]: pca_x$rotation[, 1]</span></span></code></pre></div>
<p>For a visual comparison, we can also plot
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ùõÉ</mi><mtext mathvariant="normal">ridge</mtext></msub><mi>/</mi><mo stretchy="false" form="postfix">‚à•</mo><msub><mi>ùõÉ</mi><mtext mathvariant="normal">ridge</mtext></msub><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\boldsymbol\beta_{\text{ridge}} / \|\boldsymbol\beta_{\text{ridge}}\|_2</annotation></semantics></math>
against the loadings <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ùêï</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\mathbf V_1</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="fu">plot</span>(V[, <span class="dv">1</span>], beta_ridge <span class="sc">/</span> mag_beta_ridge,</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="st">&quot;V&quot;</span>[<span class="dv">1</span>]),</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="fu">expression</span>(beta[<span class="st">&quot;ridge&quot;</span>] <span class="sc">/</span> <span class="fu">paste</span>(<span class="st">&quot;||&quot;</span>, beta, <span class="st">&quot;||&quot;</span>)[<span class="dv">2</span>]),</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>  <span class="at">pch =</span> <span class="dv">19</span></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/beta_ridge-vs-V1-plot-1.png" width="100%" style="display: block; margin: auto;" /></p>
</details>
<p>You have now seen that the loadings of the PCs can be computed from ridge regression coefficients.</p>
<p>If we introduce an additional <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mn>1</mn></msub><annotation encoding="application/x-tex">L_1</annotation></semantics></math> penalty on the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõÉ</mi><annotation encoding="application/x-tex">\boldsymbol \beta</annotation></semantics></math> coefficients, we move from ridge regression to elastic net regression. Recall that elastic net regression minimizes the criterion
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="postfix">‚à•</mo><mi>ùêò</mi><mo>‚àí</mo><mi>ùêó</mi><mi>ùõÉ</mi><msubsup><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>Œ±</mi><mi>Œª</mi><mo stretchy="false" form="postfix">‚à•</mo><mi>ùõÉ</mi><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>1</mn></msub><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>Œª</mi><mo stretchy="false" form="postfix">‚à•</mo><mi>ùõÉ</mi><msubsup><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">
\|\mathbf Y-\mathbf{X}\boldsymbol \beta\|^2_2 +  \alpha \lambda\|\boldsymbol \beta\|_1 + (1 - \alpha) \lambda\|\boldsymbol \beta\|^2_2
</annotation></semantics></math>
for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ±</mi><mo>‚àà</mo><mrow><mo stretchy="true" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\alpha \in [0,1]</annotation></semantics></math>. Whenever <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ±</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\alpha &gt; 0</annotation></semantics></math>, a sufficiently large <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math> forces some of the coefficients in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõÉ</mi><annotation encoding="application/x-tex">\boldsymbol\beta</annotation></semantics></math> to become zero.</p>
<p>Regressing the principal component <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Z</mi><mn>1</mn></msub><annotation encoding="application/x-tex">Z_1</annotation></semantics></math> on <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math> therefore sets some of the loadings <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><mn>1</mn></msub><annotation encoding="application/x-tex">V_1</annotation></semantics></math> to zero. This means that elastic net can be used to implement sparse PCA.</p>
</div>
<div id="fit-an-elastic-net-model-for-z_1.-use-alpha-0.5-and-lambda-c11-1.75-0.3.-determine-the-number-of-non-zero-loadings-for-each-choice-of-lambda.-repeat-the-same-steps-for-z_2-but-use-lambda-c5-1.5-0.15." class="section level5 unnumbered">
<h5>6. Fit an elastic net model for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Z</mi><mn>1</mn></msub><annotation encoding="application/x-tex">Z_1</annotation></semantics></math>. Use <code>alpha = 0.5</code> and <code>lambda = c(11, 1.75, 0.3)</code>. Determine the number of non-zero loadings for each choice of <code>lambda</code>. Repeat the same steps for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Z</mi><mn>2</mn></msub><annotation encoding="application/x-tex">Z_2</annotation></semantics></math>, but use <code>lambda = c(5, 1.5, 0.15)</code>.</h5>
<details>
<summary>
Solution
</summary>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># Helper function to determine number of non-zero loadings</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>num_loadings <span class="ot">&lt;-</span> <span class="cf">function</span>(fit) {</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>  lambdas <span class="ot">&lt;-</span> fit<span class="sc">$</span>lambda</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>  num_nonzero <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>  <span class="cf">for</span> (lambda <span class="cf">in</span> lambdas) {</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>    num_nonzero <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>      num_nonzero, <span class="fu">sum</span>(<span class="fu">as.vector</span>(<span class="fu">coef</span>(fit, <span class="at">s =</span> lambda))[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>    )</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>  }</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">data.frame</span>(lambdas, num_nonzero))</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>}</span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="co"># Elastic net for Z_1</span></span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a>fit_loadings1 <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, Z[, <span class="dv">1</span>], <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">lambda =</span> <span class="fu">c</span>(<span class="dv">11</span>, <span class="fl">1.75</span>, <span class="fl">0.3</span>))</span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a><span class="fu">num_loadings</span>(fit_loadings1)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["lambdas"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["num_nonzero"],"name":[2],"type":["int"],"align":["right"]}],"data":[{"1":"11.00","2":"64"},{"1":"1.75","2":"99"},{"1":"0.30","2":"144"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="co"># Elastic net for Z_2</span></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>fit_loadings2 <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, Z[, <span class="dv">2</span>], <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">lambda =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="fl">1.5</span>, <span class="fl">0.15</span>))</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="fu">num_loadings</span>(fit_loadings2)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["lambdas"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["num_nonzero"],"name":[2],"type":["int"],"align":["right"]}],"data":[{"1":"5.00","2":"44"},{"1":"1.50","2":"64"},{"1":"0.15","2":"105"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</details>
</div>
<div id="plot-the-resulting-sparse-first-and-second-pcs-and-use-different-colors-for-tumor-normal-tissue.-how-well-do-these-new-pcs-separate-the-response-classes" class="section level5 unnumbered">
<h5>7. Plot the resulting sparse first and second PCs and use different colors for tumor / normal tissue. How well do these new PCs separate the response classes?</h5>
<p>You may reuse the code from task 3 to produce 3 new plots for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Œª</mi><mtext mathvariant="normal">PC1</mtext></msub><mo>=</mo><mn>11</mn><mo>,</mo><msub><mi>Œª</mi><mtext mathvariant="normal">PC2</mtext></msub><mo>=</mo><mn>5</mn><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\lambda_{\text{PC1}} = 11, \lambda_{\text{PC2}} = 5)</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Œª</mi><mtext mathvariant="normal">PC1</mtext></msub><mo>=</mo><mn>1.75</mn><mo>,</mo><msub><mi>Œª</mi><mtext mathvariant="normal">PC2</mtext></msub><mo>=</mo><mn>1.5</mn><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\lambda_{\text{PC1}} = 1.75, \lambda_{\text{PC2}} = 1.5)</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Œª</mi><mtext mathvariant="normal">PC1</mtext></msub><mo>=</mo><mn>0.3</mn><mo>,</mo><msub><mi>Œª</mi><mtext mathvariant="normal">PC2</mtext></msub><mo>=</mo><mn>0.15</mn><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\lambda_{\text{PC1}} = 0.3, \lambda_{\text{PC2}} = 0.15)</annotation></semantics></math>. Compare this to the plot for the original PCs from task 3 and interpret.</p>
<details>
<summary>
Solution
</summary>
<p>Using base <code>R</code> plotting:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># Helper function for scatterplot between two sparse PCs</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>plot_sparse_PCA <span class="ot">&lt;-</span> <span class="cf">function</span>(loadings1, loadings2) {</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>  nonzero1 <span class="ot">&lt;-</span> <span class="fu">sum</span>(loadings1[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>  nonzero2 <span class="ot">&lt;-</span> <span class="fu">sum</span>(loadings2[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>  SPC1 <span class="ot">&lt;-</span> X <span class="sc">%*%</span> loadings1[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>  SPC2 <span class="ot">&lt;-</span> X <span class="sc">%*%</span> loadings2[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>  <span class="fu">plot</span>(</span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a>    SPC1, SPC2, <span class="at">col =</span> cols[Y], <span class="at">xlab =</span> <span class="st">&quot;SPC1&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;SPC2&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>,</span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a>    <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">40</span>, <span class="dv">40</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">60</span>, <span class="dv">95</span>),</span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a>    <span class="at">main =</span> <span class="fu">paste</span>(nonzero1, <span class="st">&quot;genes for SPC1,&quot;</span>, nonzero2, <span class="st">&quot;for SPC2&quot;</span>)</span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a>  )</span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a>  <span class="fu">legend</span>(</span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a>    <span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Normal tissue&quot;</span>, <span class="st">&quot;Tumor tissue&quot;</span>),</span>
<span id="cb18-16"><a href="#cb18-16" tabindex="-1"></a>    <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="at">col =</span> cols, <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">16</span>, <span class="dv">16</span>), <span class="at">cex =</span> <span class="dv">1</span></span>
<span id="cb18-17"><a href="#cb18-17" tabindex="-1"></a>  )</span>
<span id="cb18-18"><a href="#cb18-18" tabindex="-1"></a>}</span>
<span id="cb18-19"><a href="#cb18-19" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb18-21"><a href="#cb18-21" tabindex="-1"></a><span class="fu">plot</span>(Z[, <span class="dv">1</span>], Z[, <span class="dv">2</span>],</span>
<span id="cb18-22"><a href="#cb18-22" tabindex="-1"></a>  <span class="at">col =</span> cols[Y], <span class="at">xlab =</span> <span class="st">&quot;PC1&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;PC2&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>,</span>
<span id="cb18-23"><a href="#cb18-23" tabindex="-1"></a>  <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">40</span>, <span class="dv">40</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">60</span>, <span class="dv">95</span>),</span>
<span id="cb18-24"><a href="#cb18-24" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;All 2000 genes </span><span class="sc">\n</span><span class="st">for PC1 and PC2&quot;</span></span>
<span id="cb18-25"><a href="#cb18-25" tabindex="-1"></a>)</span>
<span id="cb18-26"><a href="#cb18-26" tabindex="-1"></a><span class="fu">legend</span>(</span>
<span id="cb18-27"><a href="#cb18-27" tabindex="-1"></a>  <span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Normal tissue&quot;</span>, <span class="st">&quot;Tumor tissue&quot;</span>),</span>
<span id="cb18-28"><a href="#cb18-28" tabindex="-1"></a>  <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="at">col =</span> cols, <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">16</span>, <span class="dv">16</span>), <span class="at">cex =</span> <span class="dv">1</span></span>
<span id="cb18-29"><a href="#cb18-29" tabindex="-1"></a>)</span>
<span id="cb18-30"><a href="#cb18-30" tabindex="-1"></a><span class="fu">plot_sparse_PCA</span>(</span>
<span id="cb18-31"><a href="#cb18-31" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings1, <span class="at">s =</span> <span class="fl">0.3</span>)),</span>
<span id="cb18-32"><a href="#cb18-32" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings2, <span class="at">s =</span> <span class="fl">0.15</span>))</span>
<span id="cb18-33"><a href="#cb18-33" tabindex="-1"></a>)</span>
<span id="cb18-34"><a href="#cb18-34" tabindex="-1"></a><span class="fu">plot_sparse_PCA</span>(</span>
<span id="cb18-35"><a href="#cb18-35" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings1, <span class="at">s =</span> <span class="fl">1.75</span>)),</span>
<span id="cb18-36"><a href="#cb18-36" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings2, <span class="at">s =</span> <span class="fl">1.5</span>))</span>
<span id="cb18-37"><a href="#cb18-37" tabindex="-1"></a>)</span>
<span id="cb18-38"><a href="#cb18-38" tabindex="-1"></a><span class="fu">plot_sparse_PCA</span>(</span>
<span id="cb18-39"><a href="#cb18-39" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings1, <span class="at">s =</span> <span class="dv">11</span>)),</span>
<span id="cb18-40"><a href="#cb18-40" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings2, <span class="at">s =</span> <span class="dv">6</span>))</span>
<span id="cb18-41"><a href="#cb18-41" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/sparse-PCA-plots-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Alternatively, using <code>ggplot</code>:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="co"># Helper function for scatterplot between two sparse PCs</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>plot_sparse_PCA <span class="ot">&lt;-</span> <span class="cf">function</span>(loadings1, loadings2) {</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>  nonzero1 <span class="ot">&lt;-</span> <span class="fu">sum</span>(loadings1[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>  nonzero2 <span class="ot">&lt;-</span> <span class="fu">sum</span>(loadings2[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>  SPC1 <span class="ot">&lt;-</span> X <span class="sc">%*%</span> loadings1[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>  SPC2 <span class="ot">&lt;-</span> X <span class="sc">%*%</span> loadings2[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">data.frame</span>(SPC1, SPC2, <span class="at">Tissue =</span> Y), <span class="fu">aes</span>(SPC1, SPC2)) <span class="sc">+</span></span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">col =</span> Tissue), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a>    <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;deepskyblue2&quot;</span>, <span class="st">&quot;coral1&quot;</span>)) <span class="sc">+</span></span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">paste</span>(nonzero1, <span class="st">&quot;genes for SPC1,&quot;</span>, nonzero2, <span class="st">&quot;for SPC2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a>    <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">60</span>, <span class="dv">95</span>) <span class="sc">+</span></span>
<span id="cb19-14"><a href="#cb19-14" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">40</span>, <span class="dv">40</span>) <span class="sc">+</span></span>
<span id="cb19-15"><a href="#cb19-15" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb19-16"><a href="#cb19-16" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>, <span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">8</span>))</span>
<span id="cb19-17"><a href="#cb19-17" tabindex="-1"></a>}</span>
<span id="cb19-18"><a href="#cb19-18" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" tabindex="-1"></a>plot1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(scores_1_2, <span class="fu">aes</span>(PC1, PC2)) <span class="sc">+</span></span>
<span id="cb19-20"><a href="#cb19-20" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">col =</span> Tissue), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb19-21"><a href="#cb19-21" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;deepskyblue2&quot;</span>, <span class="st">&quot;coral1&quot;</span>)) <span class="sc">+</span></span>
<span id="cb19-22"><a href="#cb19-22" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;All 2000 genes for PC1 and PC2&quot;</span>) <span class="sc">+</span></span>
<span id="cb19-23"><a href="#cb19-23" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">60</span>, <span class="dv">95</span>) <span class="sc">+</span></span>
<span id="cb19-24"><a href="#cb19-24" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">40</span>, <span class="dv">40</span>) <span class="sc">+</span></span>
<span id="cb19-25"><a href="#cb19-25" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb19-26"><a href="#cb19-26" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>, <span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">8</span>))</span>
<span id="cb19-27"><a href="#cb19-27" tabindex="-1"></a>plot2 <span class="ot">&lt;-</span> <span class="fu">plot_sparse_PCA</span>(</span>
<span id="cb19-28"><a href="#cb19-28" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings1, <span class="at">s =</span> <span class="fl">0.3</span>)),</span>
<span id="cb19-29"><a href="#cb19-29" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings2, <span class="at">s =</span> <span class="fl">0.15</span>))</span>
<span id="cb19-30"><a href="#cb19-30" tabindex="-1"></a>)</span>
<span id="cb19-31"><a href="#cb19-31" tabindex="-1"></a>plot3 <span class="ot">&lt;-</span> <span class="fu">plot_sparse_PCA</span>(</span>
<span id="cb19-32"><a href="#cb19-32" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings1, <span class="at">s =</span> <span class="fl">1.75</span>)),</span>
<span id="cb19-33"><a href="#cb19-33" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings2, <span class="at">s =</span> <span class="fl">1.5</span>))</span>
<span id="cb19-34"><a href="#cb19-34" tabindex="-1"></a>)</span>
<span id="cb19-35"><a href="#cb19-35" tabindex="-1"></a>plot4 <span class="ot">&lt;-</span> <span class="fu">plot_sparse_PCA</span>(</span>
<span id="cb19-36"><a href="#cb19-36" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings1, <span class="at">s =</span> <span class="dv">11</span>)),</span>
<span id="cb19-37"><a href="#cb19-37" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(fit_loadings2, <span class="at">s =</span> <span class="dv">6</span>))</span>
<span id="cb19-38"><a href="#cb19-38" tabindex="-1"></a>)</span>
<span id="cb19-39"><a href="#cb19-39" tabindex="-1"></a></span>
<span id="cb19-40"><a href="#cb19-40" tabindex="-1"></a><span class="fu">ggarrange</span>(plot1, plot2, plot3, plot4)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/ggplot-spc-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p><strong>Conclusion:</strong> Sparse PCA has succeeded in setting the uninformative genes / loadings to zero.
In separating normal and tumour tissues, SPCA performs vitually the same as PCA. By increasing <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>, more sparsity is induced in the loadings, while the overall visual impression remains comparable.
The key point here is that SPCA uses only a minor proportion of the original features to achieve the same results, suggesting that the largest variability of the data is only driven by a minority of features.</p>
</details>
<p><strong>Remark:</strong> Oftentimes, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math> is chosen in such a way that a particular number or range of nonzero loadings is obtained. This is how we proceeded above, where we considered a sequence of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>‚Äôs resulting in different levels of sparsity.
Alternatively, if you want to select <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math> in a data-driven manner, you <em>cannot</em> rely on cross-validation with the predictive MSE as used in <a href="https://statomics.github.io/HDDA/Lab3-Penalized-Regression.html#9_Exercise:_evaluate_and_compare_prediction_models">Lab 3</a>. The reason for this is that the minimal cross-validated MSE will be achieved for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œª</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda = 0</annotation></semantics></math> (or the smallest positive value that can be evaluated without numerical problems).
Instead, you can take a look at the proportion of variance that is explained by the sparse PCs to select a sensible number of nonzero loadings or a sensible <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>.</p>
</div>
</div>
</div>
<div id="lda" class="section level1" number="3">
<h1><span class="header-section-number">3</span> LDA</h1>
<p>In this section, we will perform LDA on the data by <span class="citation">Alon et al. (1999)</span> to get a clear understanding on the genes responsible for separating the tumor and normal tissue groups.</p>
<p>Remember that the LDA problem can be stated as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùêØ</mi><mo>=</mo><msub><mtext mathvariant="normal">ArgMax</mtext><mi>a</mi></msub><mfrac><mrow><msup><mi>ùêö</mi><mi>ùêì</mi></msup><mi>ùêÅ</mi><mi>ùêö</mi></mrow><mrow><msup><mi>ùêö</mi><mi>ùêì</mi></msup><mi>ùêñ</mi><mi>ùêö</mi></mrow></mfrac><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> subject to </mtext><mspace width="0.333em"></mspace></mrow><mrow><msup><mi>ùêö</mi><mi>ùêì</mi></msup><mi>ùêñ</mi><mi>ùêö</mi></mrow><mo>=</mo><mn>1</mn><mspace width="0.167em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">
\mathbf{v}
  = \text{ArgMax}_a \frac{\mathbf{a^T B a}}{\mathbf{a^T W a}}
    \text{ subject to }
    \mathbf{a^T W a} = 1 \, ,
</annotation></semantics></math></p>
<p>which is equivalent to the eigenvalue / eigenvector problem</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ùêñ</mi><mrow><mi>‚àí</mi><mn>1</mn></mrow></msup><mi>ùêÅ</mi><mi>ùêö</mi><mo>=</mo><mi>Œª</mi><mi>ùêö</mi><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mathbf W^{-1} \mathbf B \mathbf a=\lambda \mathbf a \, .
</annotation></semantics></math></p>
<p>In our case, where we only have two groups, only one solution exists.
This is the eigenvector <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mi>ùêØ</mi></mrow><annotation encoding="application/x-tex">a = \mathbf v</annotation></semantics></math> and its eigenvalue.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêØ</mi><annotation encoding="application/x-tex">\mathbf v</annotation></semantics></math> can can be interpreted in terms of which predictors are important to discriminate between the two classes.
We can then write the scores as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùêô</mi><mo>=</mo><mi>ùêó</mi><mi>ùêØ</mi><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mathbf Z=\mathbf X \mathbf v \, .
</annotation></semantics></math></p>
<div id="tasks-1" class="section level2 unnumbered">
<h2>Tasks</h2>
<div id="use-the-lda-function-from-the-mass-package-to-fit-an-lda-on-x-with-grouping-y." class="section level5 unnumbered">
<h5>1. Use the <code>lda()</code> function from the <code>MASS</code> package to fit an LDA on <code>X</code> with grouping <code>Y</code>.</h5>
<p>Note that the <code>grouping</code> has to be a factor variable.</p>
<details>
<summary>
Solution
</summary>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>alon_lda <span class="ot">&lt;-</span> <span class="fu">lda</span>(<span class="at">x =</span> X, <span class="at">grouping =</span> Y)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="co"># alternative: Y ~ X</span></span></code></pre></div>
<p>Note the warning regarding collinearity.</p>
</details>
</div>
<div id="extract-mathbf-v-from-the-lda-object." class="section level5 unnumbered">
<h5>2. Extract <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêØ</mi><annotation encoding="application/x-tex">\mathbf v</annotation></semantics></math> from the <code>lda</code> object.</h5>
<p>Hint: Have a look at the ‚ÄúValue‚Äù section of <code>?lda</code>.</p>
<details>
<summary>
Solution
</summary>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>V1 <span class="ot">&lt;-</span> alon_lda<span class="sc">$</span>scaling</span></code></pre></div>
</details>
</div>
<div id="compute-mathbf-z." class="section level5 unnumbered">
<h5>3. Compute <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêô</mi><annotation encoding="application/x-tex">\mathbf Z</annotation></semantics></math>.</h5>
<details>
<summary>
Solution
</summary>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>Z1 <span class="ot">&lt;-</span> X <span class="sc">%*%</span> V1</span></code></pre></div>
</details>
</div>
<div id="plot-the-scores-mathbf-z-against-the-response-to-see-how-well-the-lda-separates-the-tumour-and-normal-tissues-groups.-interpret-your-plot." class="section level5 unnumbered">
<h5>4. Plot the scores <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêô</mi><annotation encoding="application/x-tex">\mathbf Z</annotation></semantics></math> against the response to see how well the LDA separates the tumour and normal tissues groups. Interpret your plot.</h5>
<p>Hint: A boxplot would be an appropriate visualization, but feel free to be creative.</p>
<details>
<summary>
Solution
</summary>
<p>Using <code>ggplot</code>:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(Z1, Y), <span class="fu">aes</span>(<span class="at">x =</span> Y, <span class="at">y =</span> Z1, <span class="at">fill =</span> <span class="fu">as.factor</span>(Y))) <span class="sc">+</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> cols) <span class="sc">+</span></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Y&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Z&quot;</span>,</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Separation of normal and tumour samples by LDA&quot;</span></span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>, <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/LDA-ggboxplot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Alternatively, using base <code>R</code> plotting:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="fu">boxplot</span>(</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>  Z1 <span class="sc">~</span> Y, <span class="at">col =</span> cols, <span class="at">ylab =</span> <span class="st">&quot;Z&quot;</span>,</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Separation of normal and tumour samples by LDA&quot;</span></span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/LDA-boxplot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p><strong>Interpretation</strong>: The LDA can separate the tumour and normal tissue samples very well. In comparison, the first and second components of the (sparse) PCA (an unsupervised method) in the first part of this Lab did not discriminate the two groups nearly as well.</p>
</details>
<p>We can view
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùêô</mi><mo>=</mo><mi>ùêó</mi><mi>ùêØ</mi></mrow><annotation encoding="application/x-tex">
\mathbf Z = \mathbf X \mathbf v
</annotation></semantics></math>
as a regression of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêô</mi><annotation encoding="application/x-tex">\mathbf Z</annotation></semantics></math> on <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêó</mi><annotation encoding="application/x-tex">\mathbf X</annotation></semantics></math> with coefficient vector <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêØ</mi><annotation encoding="application/x-tex">\mathbf v</annotation></semantics></math>. The entries of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêØ</mi><annotation encoding="application/x-tex">\mathbf v</annotation></semantics></math> are non-zero for all genes.
To implement a sparse LDA, where some of the entries of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêØ</mi><annotation encoding="application/x-tex">\mathbf v</annotation></semantics></math> are set to zero, we can introduce an <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mn>1</mn></msub><annotation encoding="application/x-tex">L_1</annotation></semantics></math> penalty on <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêØ</mi><annotation encoding="application/x-tex">\mathbf v</annotation></semantics></math> and fit a Lasso regression.
The resulting <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêØ</mi><annotation encoding="application/x-tex">\mathbf v</annotation></semantics></math> will only be determined by a few interesting genes instead of all 2000.</p>
</div>
<div id="fit-a-lasso-model-for-mathbf-z-with-lambda-c0.1-0.01-0.001.-determine-the-number-of-non-zero-loadings-for-each-choice-of-lambda." class="section level5 unnumbered">
<h5>5. Fit a Lasso model for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùêô</mi><annotation encoding="application/x-tex">\mathbf Z</annotation></semantics></math> with <code>lambda = c(0.1, 0.01, 0.001)</code>. Determine the number of non-zero loadings for each choice of <code>lambda</code>.</h5>
<details>
<summary>
Solution
</summary>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>lda_loadings <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, Z1, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.02</span>, <span class="fl">0.002</span>))</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a><span class="fu">num_loadings</span>(lda_loadings)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["lambdas"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["num_nonzero"],"name":[2],"type":["int"],"align":["right"]}],"data":[{"1":"0.200","2":"18"},{"1":"0.020","2":"52"},{"1":"0.002","2":"108"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</details>
</div>
<div id="plot-the-resulting-sparse-scores-against-the-response.-are-the-smaller-subsets-of-genes-as-effective-in-separating-the-tumour-and-normal-tissue-groups-as-the-entire-set-of-genes" class="section level5 unnumbered">
<h5>6. Plot the resulting sparse scores against the response. Are the smaller subsets of genes as effective in separating the tumour and normal tissue groups as the entire set of genes?</h5>
<p>You may reuse the code from task 4 to produce 3 new plots, one for each choice of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>. Compare this to the plot for the original LDA from task 4 and interpret.</p>
<details>
<summary>
Solution
</summary>
<p>Using base <code>R</code> plotting:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a><span class="co"># Helper function for scatterplot between two sparse PCs</span></span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>plot_sparse_LDA <span class="ot">&lt;-</span> <span class="cf">function</span>(loadings) {</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>  n_nonzero <span class="ot">&lt;-</span> <span class="fu">sum</span>(loadings[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a>  SLDA <span class="ot">&lt;-</span> X <span class="sc">%*%</span> loadings[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a>  <span class="fu">boxplot</span>(</span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a>    SLDA <span class="sc">~</span> Y, <span class="at">col =</span> cols, <span class="at">ylab =</span> <span class="st">&quot;Z&quot;</span>,</span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a>    <span class="at">main =</span> <span class="fu">sprintf</span>(<span class="st">&quot;Subset of %d genes&quot;</span>, n_nonzero),</span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a>    <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a>  )</span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a>}</span>
<span id="cb26-12"><a href="#cb26-12" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb26-14"><a href="#cb26-14" tabindex="-1"></a><span class="fu">boxplot</span>(</span>
<span id="cb26-15"><a href="#cb26-15" tabindex="-1"></a>  Z1 <span class="sc">~</span> Y, <span class="at">col =</span> cols, <span class="at">ylab =</span> <span class="st">&quot;Z&quot;</span>,</span>
<span id="cb26-16"><a href="#cb26-16" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Entire set of 2000 genes&quot;</span>,</span>
<span id="cb26-17"><a href="#cb26-17" tabindex="-1"></a>  <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb26-18"><a href="#cb26-18" tabindex="-1"></a>)</span>
<span id="cb26-19"><a href="#cb26-19" tabindex="-1"></a><span class="fu">plot_sparse_LDA</span>(</span>
<span id="cb26-20"><a href="#cb26-20" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(lda_loadings, <span class="at">s =</span> <span class="fl">0.002</span>))</span>
<span id="cb26-21"><a href="#cb26-21" tabindex="-1"></a>)</span>
<span id="cb26-22"><a href="#cb26-22" tabindex="-1"></a><span class="fu">plot_sparse_LDA</span>(</span>
<span id="cb26-23"><a href="#cb26-23" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(lda_loadings, <span class="at">s =</span> <span class="fl">0.02</span>))</span>
<span id="cb26-24"><a href="#cb26-24" tabindex="-1"></a>)</span>
<span id="cb26-25"><a href="#cb26-25" tabindex="-1"></a><span class="fu">plot_sparse_LDA</span>(</span>
<span id="cb26-26"><a href="#cb26-26" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(lda_loadings, <span class="at">s =</span> <span class="fl">0.2</span>))</span>
<span id="cb26-27"><a href="#cb26-27" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/sparse-LDA-plots-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Alternatively, using <code>ggplot</code>:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="co"># Helper function for scatterplot between two sparse PCs</span></span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>plot_sparse_LDA <span class="ot">&lt;-</span> <span class="cf">function</span>(loadings) {</span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>  n_nonzero <span class="ot">&lt;-</span> <span class="fu">sum</span>(loadings[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>  SLDA <span class="ot">&lt;-</span> X <span class="sc">%*%</span> loadings[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">data.frame</span>(SLDA, Y), <span class="fu">aes</span>(<span class="at">x =</span> Y, <span class="at">y =</span> SLDA, <span class="at">fill =</span> <span class="fu">as.factor</span>(Y))) <span class="sc">+</span></span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a>    <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a>    <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> cols) <span class="sc">+</span></span>
<span id="cb27-9"><a href="#cb27-9" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Y&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Z&quot;</span>,</span>
<span id="cb27-10"><a href="#cb27-10" tabindex="-1"></a>      <span class="at">title =</span> <span class="fu">sprintf</span>(<span class="st">&quot;Subset of %d genes&quot;</span>, n_nonzero)</span>
<span id="cb27-11"><a href="#cb27-11" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb27-12"><a href="#cb27-12" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb27-13"><a href="#cb27-13" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb27-14"><a href="#cb27-14" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>, <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))  </span>
<span id="cb27-15"><a href="#cb27-15" tabindex="-1"></a>}</span>
<span id="cb27-16"><a href="#cb27-16" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" tabindex="-1"></a>plot1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="fu">data.frame</span>(Z1, Y), <span class="fu">aes</span>(<span class="at">x =</span> Y, <span class="at">y =</span> Z1, <span class="at">fill =</span> <span class="fu">as.factor</span>(Y))) <span class="sc">+</span></span>
<span id="cb27-18"><a href="#cb27-18" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb27-19"><a href="#cb27-19" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> cols) <span class="sc">+</span></span>
<span id="cb27-20"><a href="#cb27-20" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Y&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Z&quot;</span>,</span>
<span id="cb27-21"><a href="#cb27-21" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Entire set of 2000 genes&quot;</span></span>
<span id="cb27-22"><a href="#cb27-22" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb27-23"><a href="#cb27-23" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb27-24"><a href="#cb27-24" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb27-25"><a href="#cb27-25" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>, <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb27-26"><a href="#cb27-26" tabindex="-1"></a>plot2 <span class="ot">&lt;-</span> <span class="fu">plot_sparse_LDA</span>(</span>
<span id="cb27-27"><a href="#cb27-27" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(lda_loadings, <span class="at">s =</span> <span class="fl">0.002</span>))</span>
<span id="cb27-28"><a href="#cb27-28" tabindex="-1"></a>)</span>
<span id="cb27-29"><a href="#cb27-29" tabindex="-1"></a>plot3 <span class="ot">&lt;-</span> <span class="fu">plot_sparse_LDA</span>(</span>
<span id="cb27-30"><a href="#cb27-30" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(lda_loadings, <span class="at">s =</span> <span class="fl">0.02</span>))</span>
<span id="cb27-31"><a href="#cb27-31" tabindex="-1"></a>)</span>
<span id="cb27-32"><a href="#cb27-32" tabindex="-1"></a>plot4 <span class="ot">&lt;-</span> <span class="fu">plot_sparse_LDA</span>(</span>
<span id="cb27-33"><a href="#cb27-33" tabindex="-1"></a>  <span class="fu">as.vector</span>(<span class="fu">coef</span>(lda_loadings, <span class="at">s =</span> <span class="fl">0.2</span>))</span>
<span id="cb27-34"><a href="#cb27-34" tabindex="-1"></a>)</span>
<span id="cb27-35"><a href="#cb27-35" tabindex="-1"></a></span>
<span id="cb27-36"><a href="#cb27-36" tabindex="-1"></a><span class="fu">ggarrange</span>(plot1, plot2, plot3, plot4)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/sparse-LDA-ggplots-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p><strong>Conclusion:</strong> Sparse LDA performs almost identically to the original LDA in separating normal and tumour tissues. Even with only the 18 most important genes, the sparse LDA is mostly able to discriminate the two classes well.
Therefore, the separation between normal and tumour tissues is mainly driven by only a small proportion of genes.</p>
</details>
</div>
</div>
<div id="bonus-evaluation-of-lda-as-a-predictive-classifier" class="section level2 unnumbered">
<h2>Bonus: Evaluation of LDA as a predictive classifier</h2>
<p>We use 10-fold cross-validation to evaluate the predictive accuracy of classifications from the original LDA on all 2000 genes and the SLDA on the three smaller subsets of genes.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">914751</span>)</span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a><span class="co"># Helper function to compute accuracy given v, X, and Y</span></span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a>lda_accuracy <span class="ot">&lt;-</span> <span class="cf">function</span>(v, X, Y) {</span>
<span id="cb28-5"><a href="#cb28-5" tabindex="-1"></a>  preds <span class="ot">&lt;-</span> (X <span class="sc">%*%</span> v) <span class="sc">&gt;</span> <span class="dv">0</span></span>
<span id="cb28-6"><a href="#cb28-6" tabindex="-1"></a>  obs <span class="ot">&lt;-</span> Y <span class="sc">==</span> <span class="st">&quot;t&quot;</span></span>
<span id="cb28-7"><a href="#cb28-7" tabindex="-1"></a>  <span class="fu">return</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">mean</span>(<span class="fu">abs</span>(preds <span class="sc">-</span> obs)))</span>
<span id="cb28-8"><a href="#cb28-8" tabindex="-1"></a>}</span>
<span id="cb28-9"><a href="#cb28-9" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" tabindex="-1"></a>acc_full <span class="ot">&lt;-</span> acc_small <span class="ot">&lt;-</span> acc_smaller <span class="ot">&lt;-</span> acc_smallest <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb28-11"><a href="#cb28-11" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" tabindex="-1"></a><span class="co"># Randomly split the data into k folds</span></span>
<span id="cb28-13"><a href="#cb28-13" tabindex="-1"></a>folds <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">length.out =</span> <span class="fu">length</span>(Y)))</span>
<span id="cb28-14"><a href="#cb28-14" tabindex="-1"></a></span>
<span id="cb28-15"><a href="#cb28-15" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb28-16"><a href="#cb28-16" tabindex="-1"></a>  <span class="co"># Assign the train and validation set for this fold</span></span>
<span id="cb28-17"><a href="#cb28-17" tabindex="-1"></a>  val_idx <span class="ot">&lt;-</span> <span class="fu">which</span>(folds <span class="sc">==</span> k)</span>
<span id="cb28-18"><a href="#cb28-18" tabindex="-1"></a>  train_idx <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="fu">seq_len</span>(<span class="fu">length</span>(Y)), val_idx)</span>
<span id="cb28-19"><a href="#cb28-19" tabindex="-1"></a>  X_train <span class="ot">&lt;-</span> X[train_idx, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb28-20"><a href="#cb28-20" tabindex="-1"></a>  Y_train <span class="ot">&lt;-</span> Y[train_idx]</span>
<span id="cb28-21"><a href="#cb28-21" tabindex="-1"></a>  X_val <span class="ot">&lt;-</span> X[val_idx, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb28-22"><a href="#cb28-22" tabindex="-1"></a>  Y_val <span class="ot">&lt;-</span> Y[val_idx]</span>
<span id="cb28-23"><a href="#cb28-23" tabindex="-1"></a></span>
<span id="cb28-24"><a href="#cb28-24" tabindex="-1"></a>  <span class="co"># Fit the LDA</span></span>
<span id="cb28-25"><a href="#cb28-25" tabindex="-1"></a>  lda_fold <span class="ot">&lt;-</span> <span class="fu">lda</span>(<span class="at">x =</span> X_train, <span class="at">grouping =</span> Y_train)</span>
<span id="cb28-26"><a href="#cb28-26" tabindex="-1"></a>  <span class="co"># Fit the SLDA with three levels of sparsity</span></span>
<span id="cb28-27"><a href="#cb28-27" tabindex="-1"></a>  Z_fold <span class="ot">&lt;-</span> X_train <span class="sc">%*%</span> lda_fold<span class="sc">$</span>scaling</span>
<span id="cb28-28"><a href="#cb28-28" tabindex="-1"></a>  lasso_fold <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X_train, Z_fold, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.02</span>, <span class="fl">0.002</span>))</span>
<span id="cb28-29"><a href="#cb28-29" tabindex="-1"></a>  <span class="co"># Evaluate the accuracy of all four models on the validation set</span></span>
<span id="cb28-30"><a href="#cb28-30" tabindex="-1"></a>  acc_full <span class="ot">&lt;-</span> <span class="fu">c</span>(acc_full, <span class="fu">lda_accuracy</span>(lda_fold<span class="sc">$</span>scaling, X_val, Y_val))</span>
<span id="cb28-31"><a href="#cb28-31" tabindex="-1"></a>  acc_small <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb28-32"><a href="#cb28-32" tabindex="-1"></a>    acc_small,</span>
<span id="cb28-33"><a href="#cb28-33" tabindex="-1"></a>    <span class="fu">lda_accuracy</span>(<span class="fu">as.vector</span>(<span class="fu">coef</span>(lasso_fold, <span class="at">s =</span> <span class="fl">0.002</span>))[<span class="sc">-</span><span class="dv">1</span>], X_val, Y_val)</span>
<span id="cb28-34"><a href="#cb28-34" tabindex="-1"></a>  )</span>
<span id="cb28-35"><a href="#cb28-35" tabindex="-1"></a>  acc_smaller <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb28-36"><a href="#cb28-36" tabindex="-1"></a>    acc_smaller,</span>
<span id="cb28-37"><a href="#cb28-37" tabindex="-1"></a>    <span class="fu">lda_accuracy</span>(<span class="fu">as.vector</span>(<span class="fu">coef</span>(lasso_fold, <span class="at">s =</span> <span class="fl">0.02</span>))[<span class="sc">-</span><span class="dv">1</span>], X_val, Y_val)</span>
<span id="cb28-38"><a href="#cb28-38" tabindex="-1"></a>  )</span>
<span id="cb28-39"><a href="#cb28-39" tabindex="-1"></a>  acc_smallest <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb28-40"><a href="#cb28-40" tabindex="-1"></a>    acc_smallest,</span>
<span id="cb28-41"><a href="#cb28-41" tabindex="-1"></a>    <span class="fu">lda_accuracy</span>(<span class="fu">as.vector</span>(<span class="fu">coef</span>(lasso_fold, <span class="at">s =</span> <span class="fl">0.2</span>))[<span class="sc">-</span><span class="dv">1</span>], X_val, Y_val)</span>
<span id="cb28-42"><a href="#cb28-42" tabindex="-1"></a>  )</span>
<span id="cb28-43"><a href="#cb28-43" tabindex="-1"></a>}</span>
<span id="cb28-44"><a href="#cb28-44" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-45"><a href="#cb28-45" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-46"><a href="#cb28-46" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-47"><a href="#cb28-47" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-48"><a href="#cb28-48" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-49"><a href="#cb28-49" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-50"><a href="#cb28-50" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-51"><a href="#cb28-51" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-52"><a href="#cb28-52" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-53"><a href="#cb28-53" tabindex="-1"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span>
<span id="cb28-54"><a href="#cb28-54" tabindex="-1"></a></span>
<span id="cb28-55"><a href="#cb28-55" tabindex="-1"></a><span class="fu">data.frame</span>(</span>
<span id="cb28-56"><a href="#cb28-56" tabindex="-1"></a>  <span class="at">LDA =</span> <span class="fu">c</span>(<span class="st">&quot;original&quot;</span>, <span class="st">&quot;sparse&quot;</span>, <span class="st">&quot;sparser&quot;</span>, <span class="st">&quot;sparsest&quot;</span>),</span>
<span id="cb28-57"><a href="#cb28-57" tabindex="-1"></a>  <span class="at">accuracy =</span> <span class="fu">c</span>(</span>
<span id="cb28-58"><a href="#cb28-58" tabindex="-1"></a>    <span class="fu">mean</span>(acc_full), <span class="fu">mean</span>(acc_small), <span class="fu">mean</span>(acc_smaller), <span class="fu">mean</span>(acc_smallest)</span>
<span id="cb28-59"><a href="#cb28-59" tabindex="-1"></a>  )</span>
<span id="cb28-60"><a href="#cb28-60" tabindex="-1"></a>)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["LDA"],"name":[1],"type":["chr"],"align":["left"]},{"label":["accuracy"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"original","2":"0.7619048"},{"1":"sparse","2":"0.8095238"},{"1":"sparser","2":"0.7785714"},{"1":"sparsest","2":"0.8428571"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<div id="additional-resources" class="section level1 unnumbered">
<h1>Additional resources</h1>
<ul>
<li>Section 4.3 (LDA) and 14.5.5 (SPCA) of <span class="citation">Hastie, Tibshirani, and Friedman (2009)</span></li>
<li>For a simple explanation of the concept and interpretation of LDA (and other statistical methods), have a look at <a href="https://www.youtube.com/watch?v=azXCzI57Yfc" class="uri">https://www.youtube.com/watch?v=azXCzI57Yfc</a></li>
</ul>
</div>
<div id="session-info" class="section level1 unnumbered">
<h1>Session info</h1>
<details>
<summary>
Session info
</summary>
<pre><code>#&gt; [1] &quot;2025-11-06 10:03:36 CET&quot;
#&gt; ‚îÄ Session info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#&gt;  setting  value
#&gt;  version  R version 4.5.2 (2025-10-31)
#&gt;  os       macOS Sequoia 15.6
#&gt;  system   aarch64, darwin20
#&gt;  ui       X11
#&gt;  language (EN)
#&gt;  collate  en_US.UTF-8
#&gt;  ctype    en_US.UTF-8
#&gt;  tz       Europe/Brussels
#&gt;  date     2025-11-06
#&gt;  pandoc   3.6.3 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)
#&gt;  quarto   1.7.32 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/quarto
#&gt; 
#&gt; ‚îÄ Packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#&gt;  package      * version date (UTC) lib source
#&gt;  abind          1.4-8   2024-09-12 [1] CRAN (R 4.5.0)
#&gt;  backports      1.5.0   2024-05-23 [1] CRAN (R 4.5.0)
#&gt;  bookdown       0.45    2025-10-03 [1] CRAN (R 4.5.0)
#&gt;  broom          1.0.10  2025-09-13 [1] CRAN (R 4.5.0)
#&gt;  bslib          0.9.0   2025-01-30 [1] CRAN (R 4.5.0)
#&gt;  cachem         1.1.0   2024-05-16 [1] CRAN (R 4.5.0)
#&gt;  car            3.1-3   2024-09-27 [1] CRAN (R 4.5.0)
#&gt;  carData        3.0-5   2022-01-06 [1] CRAN (R 4.5.0)
#&gt;  cli            3.6.5   2025-04-23 [1] CRAN (R 4.5.0)
#&gt;  codetools      0.2-20  2024-03-31 [1] CRAN (R 4.5.2)
#&gt;  cowplot        1.2.0   2025-07-07 [1] CRAN (R 4.5.0)
#&gt;  digest         0.6.37  2024-08-19 [1] CRAN (R 4.5.0)
#&gt;  dplyr          1.1.4   2023-11-17 [1] CRAN (R 4.5.0)
#&gt;  evaluate       1.0.5   2025-08-27 [1] CRAN (R 4.5.0)
#&gt;  farver         2.1.2   2024-05-13 [1] CRAN (R 4.5.0)
#&gt;  fastmap        1.2.0   2024-05-15 [1] CRAN (R 4.5.0)
#&gt;  foreach        1.5.2   2022-02-02 [1] CRAN (R 4.5.0)
#&gt;  Formula        1.2-5   2023-02-24 [1] CRAN (R 4.5.0)
#&gt;  generics       0.1.4   2025-05-09 [1] CRAN (R 4.5.0)
#&gt;  ggplot2      * 4.0.0   2025-09-11 [1] CRAN (R 4.5.0)
#&gt;  ggpubr       * 0.6.2   2025-10-17 [1] CRAN (R 4.5.0)
#&gt;  ggsignif       0.6.4   2022-10-13 [1] CRAN (R 4.5.0)
#&gt;  glmnet       * 4.1-10  2025-07-17 [1] CRAN (R 4.5.0)
#&gt;  glue           1.8.0   2024-09-30 [1] CRAN (R 4.5.0)
#&gt;  gridExtra    * 2.3     2017-09-09 [1] CRAN (R 4.5.0)
#&gt;  gtable         0.3.6   2024-10-25 [1] CRAN (R 4.5.0)
#&gt;  HDDAData     * 1.0.1   2025-11-06 [1] Github (statOmics/HDDAData@b832c71)
#&gt;  htmltools      0.5.8.1 2024-04-04 [1] CRAN (R 4.5.0)
#&gt;  iterators      1.0.14  2022-02-05 [1] CRAN (R 4.5.0)
#&gt;  jquerylib      0.1.4   2021-04-26 [1] CRAN (R 4.5.0)
#&gt;  jsonlite       2.0.0   2025-03-27 [1] CRAN (R 4.5.0)
#&gt;  knitr          1.50    2025-03-16 [1] CRAN (R 4.5.0)
#&gt;  labeling       0.4.3   2023-08-29 [1] CRAN (R 4.5.0)
#&gt;  lattice        0.22-7  2025-04-02 [1] CRAN (R 4.5.2)
#&gt;  lifecycle      1.0.4   2023-11-07 [1] CRAN (R 4.5.0)
#&gt;  magrittr       2.0.4   2025-09-12 [1] CRAN (R 4.5.0)
#&gt;  MASS         * 7.3-65  2025-02-28 [1] CRAN (R 4.5.2)
#&gt;  Matrix       * 1.7-4   2025-08-28 [1] CRAN (R 4.5.2)
#&gt;  pillar         1.11.1  2025-09-17 [1] CRAN (R 4.5.0)
#&gt;  pkgconfig      2.0.3   2019-09-22 [1] CRAN (R 4.5.0)
#&gt;  purrr          1.2.0   2025-11-04 [1] CRAN (R 4.5.0)
#&gt;  R6             2.6.1   2025-02-15 [1] CRAN (R 4.5.0)
#&gt;  RColorBrewer   1.1-3   2022-04-03 [1] CRAN (R 4.5.0)
#&gt;  Rcpp           1.1.0   2025-07-02 [1] CRAN (R 4.5.0)
#&gt;  rlang          1.1.6   2025-04-11 [1] CRAN (R 4.5.0)
#&gt;  rmarkdown      2.30    2025-09-28 [1] CRAN (R 4.5.0)
#&gt;  rstatix        0.7.3   2025-10-18 [1] CRAN (R 4.5.0)
#&gt;  rstudioapi     0.17.1  2024-10-22 [1] CRAN (R 4.5.0)
#&gt;  S7             0.2.0   2024-11-07 [1] CRAN (R 4.5.0)
#&gt;  sass           0.4.10  2025-04-11 [1] CRAN (R 4.5.0)
#&gt;  scales         1.4.0   2025-04-24 [1] CRAN (R 4.5.0)
#&gt;  sessioninfo    1.2.3   2025-02-05 [1] CRAN (R 4.5.0)
#&gt;  shape          1.4.6.1 2024-02-23 [1] CRAN (R 4.5.0)
#&gt;  survival       3.8-3   2024-12-17 [1] CRAN (R 4.5.2)
#&gt;  tibble         3.3.0   2025-06-08 [1] CRAN (R 4.5.0)
#&gt;  tidyr          1.3.1   2024-01-24 [1] CRAN (R 4.5.0)
#&gt;  tidyselect     1.2.1   2024-03-11 [1] CRAN (R 4.5.0)
#&gt;  vctrs          0.6.5   2023-12-01 [1] CRAN (R 4.5.0)
#&gt;  withr          3.0.2   2024-10-28 [1] CRAN (R 4.5.0)
#&gt;  xfun           0.54    2025-10-30 [1] CRAN (R 4.5.0)
#&gt;  yaml           2.3.10  2024-07-26 [1] CRAN (R 4.5.0)
#&gt; 
#&gt;  [1] /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library
#&gt;  * ‚îÄ‚îÄ Packages attached to the search path.
#&gt; 
#&gt; ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</code></pre>
</details>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-alon1999broad" class="csl-entry">
Alon, Uri, Naama Barkai, Daniel A Notterman, Kurt Gish, Suzanne Ybarra, Daniel Mack, and Arnold J Levine. 1999. <span>‚ÄúBroad Patterns of Gene Expression Revealed by Clustering Analysis of Tumor and Normal Colon Tissues Probed by Oligonucleotide Arrays.‚Äù</span> <em>Proceedings of the National Academy of Sciences</em> 96 (12): 6745‚Äì50.
</div>
<div id="ref-esl-book" class="csl-entry">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The Elements of Statistical Learning</em>. 2nd ed. Springer.
</div>
</div>
</div>

<div id="rmd-source-code">---
title: "Lab 4: Sparse PCA and LDA"
subtitle: "High Dimensional Data Analysis practicals"
author: "Adapted by Milan Malfait and Leo Fuhrhop"
date: "18 Nov 2021 <br/> (Last updated: 2025-11-06)"
references:
- id: alon1999broad
  type: article-journal
  author:
  - family: Alon
    given: Uri
  - family: Barkai
    given: Naama
  - family: Notterman
    given: Daniel A
  - family: Gish
    given: Kurt
  - family: Ybarra
    given: Suzanne
  - family: Mack
    given: Daniel
  - family: Levine
    given: Arnold J
  issued:
  - year: 1999
  title: Broad patterns of gene expression revealed by clustering analysis of tumor
    and normal colon tissues probed by oligonucleotide arrays
  container-title: Proceedings of the National Academy of Sciences
  publisher: National Acad Sciences
  page: 6745-6750
  volume: '96'
  issue: '12'
- id: esl-book
  type: book
  author:
  - family: Hastie
    given: Trevor
  - family: Tibshirani
    given: Robert
  - family: Friedman
    given: Jerome
  issued:
  - year: 2009
  title: The Elements of Statistical Learning
  publisher: Springer
  edition: 2nd
---

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.width = 8,
  fig.asp = 0.618,
  out.width = "100%"
)
```

### [Change log](https://github.com/statOmics/HDDA/commits/master/Lab4-Sparse-PCA-LDA.Rmd) {-}

***

```{r libraries, warning=FALSE, message=FALSE}
## install packages with:
# install.packages(c("glmnet", "MASS", "ggplot2", "gridExtra", "ggpubr"))
# if (!requireNamespace("remotes", quietly = TRUE)) {
#     install.packages("remotes")
# }
# remotes::install_github("statOmics/HDDAData")

library(glmnet)
library(MASS)
library(HDDAData)
library(ggplot2)
library(gridExtra)
library(ggpubr)
```


# Introduction

**In this lab session we will look at the following topics**

  - Methods to set some of the loadings exactly to zero in a PCA
  - Use `glmnet()` to add penalties on principal component loadings
  - Use LDA to understand differences between groups in a high dimensional space

## The dataset {-}

In this practical session, we use the dataset by @alon1999broad on gene
expression levels in 40 tumour and 22 normal colon tissue samples.  They checked
a total of 6500 human genes using the Affymetrix oligonucleotide array.

You can load the data in as follows:

```{r load-data}
data("Alon1999")
str(Alon1999[, 1:10])
dim(Alon1999)
table(Alon1999$Y)
```

The dataset contains one variable named `Y` with the values `t` and `n`.  This
variable indicates whether the sample came from tumourous (`t`) or normal (`n`)
tissue.  For more information on this dataset, see `?Alon1999`.

The goal of this practical is to find the best subset / combination of genes to detect tumourous tissue.
As in @alon1999broad, we use the 2000 genes with the highest minimal intensity
across the samples.

# Sparse PCA

Begin by constructing the data matrix `X`, which contains the centered and scaled predictors,
and the response variable `Y` as a binary factor.

```{r}
X <- scale(Alon1999[, -1], center = TRUE, scale = TRUE)
Y <- as.factor(Alon1999[, 1])
```

Use these objects to solve the following exercises.

## Tasks {-}

##### 1. Perform a SVD on `X` and store the scores of the PCs. {-}

<details><summary>Solution</summary>

Using `svd`:

```{r}
svd_X <- svd(X)
Z <- svd_X$u %*% diag(svd_X$d) # Calculate the scores
V <- svd_X$v                 # Calculate the loadings
```

Using `prcomp`:

```{r}
# X is already centered and scaled so no need to do again
pca_x <- prcomp(X, center = FALSE, scale. = FALSE)
# The scores are given by `pca_x$x`, the loadings are `pca_x$rotation`
```

</details>


##### 2. Produce a scree plot and confirm that the first and second PCs can approximate the data to some extent. {-}

Recall from [Lab 2](https://statomics.github.io/HDDA/Lab2-PCA.html#Tasks) that a scree plot displays the proportion of variance explained by each PC.

<details><summary>Solution</summary>

Calculate the proportion of variance explained by each PC.

```{r pca-var-prop}
var_explained <- pca_x$sdev^2 / sum(pca_x$sdev^2)
# alternative: svd_X$d^2 / sum(svd_X$d^2)

# Create dataframe for plotting
prop_var <- data.frame(PC = 1:ncol(pca_x$x), Var = var_explained)
# alternative: PC = ncol(Z)
```

Visualize with a scree plot using `ggplot2`:

```{r pca-scree-ggplot}
ggplot(prop_var, aes(PC, Var)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 2.5, col = "firebrick") +
  scale_x_continuous(breaks = seq(0, 60, by = 5)) +
  labs(
    y = "Proportion of variance",
    title = "Proportion of variance explained by each PC"
  ) +
  theme_minimal()
```

Alternatively, using base `R` plotting:

```{r pca-scree-plot}
plot(prop_var$PC, prop_var$Var,
  type = "b", ylab = "Proportion of variance", xlab = "PC",
)
title("Proportion of variance explained by each PC")
abline(v = 2.5, col = "firebrick")
```

About 55% of the variance in the data are explained by the first and second PCs.

```{r pca-cumulative-prop-var}
cumsum(prop_var$Var)[1:10]
```

</details>


##### 3. Plot the first two PCs and use different colours for tumor / normal tissue. {-}

Due to the large number of features, the biplot would be difficult to interpret. A simple scatterplot, separated by tumor / normal tissue, is more informative in this setting.

<details><summary>Solution</summary>

```{r pca-tissue-ggplot}
scores_1_2 <- data.frame(PC1 = pca_x$x[, 1], PC2 = pca_x$x[, 2], Tissue = Y)
# Alternative: retrieve scores from Z[, 1], Z[, 2]

ggplot(scores_1_2, aes(PC1, PC2)) +
  geom_point(aes(col = Tissue), size = 2) +
  scale_color_manual(values = c("deepskyblue2", "coral1")) +
  theme_minimal() +
  theme(aspect.ratio = 0.8, legend.position = "top")
```

Alternatively, using base `R` plotting:

```{r pca-tissue-plot}
cols <- c("n" = "deepskyblue2", "t" = "coral1")
plot(scores_1_2$PC1, scores_1_2$PC2,
  col = cols[Y],
  xlab = "PC1", ylab = "PC2", pch = 19
)
legend("topleft", c("Normal", "Tumor"),
  col = cols,
  pch = 19, title = "Tissue"
)
```

__Interpretation:__ using only the first 2 PCs does not seem to separate the tumor and normal cases clearly.

</details>


##### 4. Plot histograms of the loadings of the first and second PCs. Interpret. {-}

<details><summary>Solution</summary>

```{r pca-loading-ggplot}
loadings_1_2 <- data.frame(
  loadings_1 = pca_x$rotation[, 1], loadings_2 = pca_x$rotation[, 2]
)
# alternative: loadings_1 = V[, 1], loadings_2 = V[, 2]

# First plot (PC1)
p1 <- ggplot(loadings_1_2, aes(x = loadings_1)) +
  geom_histogram(bins = 50, fill = "grey80", color = "black") +
  geom_vline(
    xintercept = quantile(loadings_1_2$loadings_1, 0.95),
    color = "firebrick",
    linewidth = 1.2
  ) +
  labs(x = "PC 1 loadings", y = "Count", title = NULL) +
  theme_minimal(base_size = 14)

# Second plot (PC2)
p2 <- ggplot(loadings_1_2, aes(x = loadings_2)) +
  geom_histogram(bins = 50, fill = "grey80", color = "black") +
  geom_vline(
    xintercept = quantile(loadings_1_2$loadings_2, c(0.05, 0.95)),
    color = "firebrick",
    linewidth = 1.2
  ) +
  labs(x = "PC 2 loadings", y = "Count", title = NULL) +
  theme_minimal(base_size = 14)

# Arrange plots vertically
grid.arrange(p1, p2, ncol = 1)
```

Alternatively, using base `R` plotting:

```{r pca-loadings-plot}
par(mfrow = c(2, 1))

# First plot (PC1)
hist(loadings_1_2$loadings_1, breaks = 50, xlab = "PC 1 loadings", main = "")
# Add vertical line at 95% quantile
abline(v = quantile(loadings_1_2$loadings_1, 0.95), col = "firebrick", lwd = 2)

# Second plot (PC2)
hist(loadings_1_2$loadings_2, breaks = 50, xlab = "PC 2 loadings", main = "")
abline(v = c(
  quantile(loadings_1_2$loadings_2, 0.05),
  quantile(loadings_1_2$loadings_2, 0.95)
), col = "firebrick", lwd = 2)
```

Vertical lines were added at the 95th percentile for PC1 and the 5th and 95th percentiles for PC2 to reflect where the largest (in absolute value) loadings are situated (no negative loadings for PC1, so only showing the 95th percentile).

__Interpretation:__ remember that the PC loadings reflect the *contributions* of each feature (in this case: gene) to the PC.
From these histograms it should be clear that only a minor fraction of the genes are really driving these first 2 PCs, especially for PC2 (where the bulk of genes has loadings close to 0).

</details>

We know that the first PC $\mathbf{Z_1}$ is given by
$$
\mathbf{Z_1}=\mathbf{X} \mathbf{V_1} \, ,
$$

where $\mathbf{V_1}$ are the loadings of the first PC. By setting $\boldsymbol{\beta} = \mathbf{V_1}$ and $Y = Z_1$, we can express this as the regression

$$
\mathbf{Y}=\mathbf{X}\boldsymbol{\beta} \, .
$$

Recall that the ridge regression solution for $\boldsymbol{\beta}$ is given by

$$
\boldsymbol{\beta}_{\text{ridge}} = (\mathbf{X^TX}+\lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf Y \, .
$$

##### 5. Replace $\mathbf{Y}$ with $\mathbf{Z_1}$ and verify numerically in `R` that  {-}
  $$
  \mathbf V_1 =
    \frac{\boldsymbol\beta_{\text{ridge}}}{\|\boldsymbol\beta_{\text{ridge}}\|_2} \, .
  $$

You may use any $\lambda > 0$ of your choice. Remember that $\|\boldsymbol\beta_{\text{ridge}}\|_2 = \sqrt{\boldsymbol\beta_{\text{ridge}}^T \boldsymbol\beta_{\text{ridge}}} = \sqrt{\sum_{j=1}^p \beta_j^2}$.

<details><summary>Solution</summary>

```{r, cache=TRUE}
p <- dim(X)[2]
tXX_lambda_I <- t(X) %*% X + 2 * diag(p)
# This might take a while to calculate
beta_ridge <- solve(tXX_lambda_I) %*% t(X) %*% Z[, 1]
mag_beta_ridge <- sqrt(sum(beta_ridge^2))
max(abs(V[, 1] - beta_ridge / mag_beta_ridge))
# alternative for V[, 1]: pca_x$rotation[, 1]
```

For a visual comparison, we can also plot
$\boldsymbol\beta_{\text{ridge}} / \|\boldsymbol\beta_{\text{ridge}}\|_2$
against the loadings $\mathbf V_1$.

```{r beta_ridge-vs-V1-plot}
par(mfrow = c(1, 1))

plot(V[, 1], beta_ridge / mag_beta_ridge,
  xlab = expression("V"[1]),
  ylab = expression(beta["ridge"] / paste("||", beta, "||")[2]),
  pch = 19
)
```

</details>

You have now seen that the loadings of the PCs can be computed from ridge regression coefficients.

If we introduce an additional $L_1$ penalty on the $\boldsymbol \beta$ coefficients, we move from ridge regression to elastic net regression. Recall that elastic net regression minimizes the criterion
$$
\|\mathbf Y-\mathbf{X}\boldsymbol \beta\|^2_2 +  \alpha \lambda\|\boldsymbol \beta\|_1 + (1 - \alpha) \lambda\|\boldsymbol \beta\|^2_2
$$
for $\alpha \in [0,1]$. Whenever $\alpha > 0$, a sufficiently large $\lambda$ forces some of the coefficients in $\boldsymbol\beta$ to become zero.

Regressing the principal component $Z_1$ on $X$ therefore sets some of the loadings $V_1$ to zero. This means that elastic net can be used to implement sparse PCA. 

##### 6. Fit an elastic net model for $Z_1$. Use `alpha = 0.5` and `lambda = c(11, 1.75, 0.3)`. Determine the number of non-zero loadings for each choice of `lambda`. Repeat the same steps for $Z_2$, but use `lambda = c(5, 1.5, 0.15)`. {-}

<details><summary>Solution</summary>

```{r PC-glmnet}
# Helper function to determine number of non-zero loadings
num_loadings <- function(fit) {
  lambdas <- fit$lambda
  num_nonzero <- NULL
  for (lambda in lambdas) {
    num_nonzero <- c(
      num_nonzero, sum(as.vector(coef(fit, s = lambda))[-1] != 0)
    )
  }
  return(data.frame(lambdas, num_nonzero))
}

# Elastic net for Z_1
fit_loadings1 <- glmnet(X, Z[, 1], alpha = 0.5, lambda = c(11, 1.75, 0.3))
num_loadings(fit_loadings1)

# Elastic net for Z_2
fit_loadings2 <- glmnet(X, Z[, 2], alpha = 0.5, lambda = c(5, 1.5, 0.15))
num_loadings(fit_loadings2)
```

</details>

##### 7. Plot the resulting sparse first and second PCs and use different colors for tumor / normal tissue. How well do these new PCs separate the response classes? {-}

You may reuse the code from task 3 to produce 3 new plots for $(\lambda_{\text{PC1}} = 11, \lambda_{\text{PC2}} = 5)$, $(\lambda_{\text{PC1}} = 1.75, \lambda_{\text{PC2}} = 1.5)$ and $(\lambda_{\text{PC1}} = 0.3, \lambda_{\text{PC2}} = 0.15)$. Compare this to the plot for the original PCs from task 3 and interpret.

<details><summary>Solution</summary>

Using base `R` plotting:

```{r sparse-PCA-plots, fig.width = 9}
# Helper function for scatterplot between two sparse PCs
plot_sparse_PCA <- function(loadings1, loadings2) {
  nonzero1 <- sum(loadings1[-1] != 0)
  nonzero2 <- sum(loadings2[-1] != 0)

  SPC1 <- X %*% loadings1[-1]
  SPC2 <- X %*% loadings2[-1]

  plot(
    SPC1, SPC2, col = cols[Y], xlab = "SPC1", ylab = "SPC2", pch = 16,
    ylim = c(-40, 40), xlim = c(-60, 95),
    main = paste(nonzero1, "genes for SPC1,", nonzero2, "for SPC2")
  )
  legend(
    "topleft", legend = c("Normal tissue", "Tumor tissue"),
    bty = "n", col = cols, pch = c(16, 16), cex = 1
  )
}

par(mfrow = c(2, 2))
plot(Z[, 1], Z[, 2],
  col = cols[Y], xlab = "PC1", ylab = "PC2", pch = 16,
  ylim = c(-40, 40), xlim = c(-60, 95),
  main = "All 2000 genes \nfor PC1 and PC2"
)
legend(
  "topleft", legend = c("Normal tissue", "Tumor tissue"),
  bty = "n", col = cols, pch = c(16, 16), cex = 1
)
plot_sparse_PCA(
  as.vector(coef(fit_loadings1, s = 0.3)),
  as.vector(coef(fit_loadings2, s = 0.15))
)
plot_sparse_PCA(
  as.vector(coef(fit_loadings1, s = 1.75)),
  as.vector(coef(fit_loadings2, s = 1.5))
)
plot_sparse_PCA(
  as.vector(coef(fit_loadings1, s = 11)),
  as.vector(coef(fit_loadings2, s = 6))
)
```

Alternatively, using `ggplot`:

```{r ggplot-spc}
# Helper function for scatterplot between two sparse PCs
plot_sparse_PCA <- function(loadings1, loadings2) {
  nonzero1 <- sum(loadings1[-1] != 0)
  nonzero2 <- sum(loadings2[-1] != 0)

  SPC1 <- X %*% loadings1[-1]
  SPC2 <- X %*% loadings2[-1]

  ggplot(data.frame(SPC1, SPC2, Tissue = Y), aes(SPC1, SPC2)) +
    geom_point(aes(col = Tissue), size = 2) +
    scale_color_manual(values = c("deepskyblue2", "coral1")) +
    labs(title = paste(nonzero1, "genes for SPC1,", nonzero2, "for SPC2")) +
    xlim(-60, 95) +
    ylim(-40, 40) +
    theme_minimal() +
    theme(legend.position = "bottom", text = element_text(size = 8))
}

plot1 <- ggplot(scores_1_2, aes(PC1, PC2)) +
  geom_point(aes(col = Tissue), size = 2) +
  scale_color_manual(values = c("deepskyblue2", "coral1")) +
  labs(title = "All 2000 genes for PC1 and PC2") +
  xlim(-60, 95) +
  ylim(-40, 40) +
  theme_minimal() +
  theme(legend.position = "bottom", text = element_text(size = 8))
plot2 <- plot_sparse_PCA(
  as.vector(coef(fit_loadings1, s = 0.3)),
  as.vector(coef(fit_loadings2, s = 0.15))
)
plot3 <- plot_sparse_PCA(
  as.vector(coef(fit_loadings1, s = 1.75)),
  as.vector(coef(fit_loadings2, s = 1.5))
)
plot4 <- plot_sparse_PCA(
  as.vector(coef(fit_loadings1, s = 11)),
  as.vector(coef(fit_loadings2, s = 6))
)

ggarrange(plot1, plot2, plot3, plot4)
```

__Conclusion:__ Sparse PCA has succeeded in setting the uninformative genes / loadings to zero. 
In separating normal and tumour tissues, SPCA performs vitually the same as PCA. By increasing $\lambda$, more sparsity is induced in the loadings, while the overall visual impression remains comparable. 
The key point here is that SPCA uses only a minor proportion of the original features to achieve the same results, suggesting that the largest variability of the data is only driven by a minority of features.

</details>

__Remark:__ Oftentimes, $\lambda$ is chosen in such a way that a particular number or range of nonzero loadings is obtained. This is how we proceeded above, where we considered a sequence of $\lambda$'s resulting in different levels of sparsity.
Alternatively, if you want to select $\lambda$ in a data-driven manner, you *cannot* rely on cross-validation with the predictive MSE as used in [Lab 3](https://statomics.github.io/HDDA/Lab3-Penalized-Regression.html#9_Exercise:_evaluate_and_compare_prediction_models). The reason for this is that the minimal cross-validated MSE will be achieved for $\lambda = 0$ (or the smallest positive value that can be evaluated without numerical problems).
Instead, you can take a look at the proportion of variance that is explained by the sparse PCs to select a sensible number of nonzero loadings or a sensible $\lambda$. 


# LDA

In this section, we will perform LDA on the data by @alon1999broad to get a clear understanding on the genes responsible for separating the tumor and normal tissue groups.

Remember that the LDA problem can be stated as

$$
\mathbf{v}
  = \text{ArgMax}_a \frac{\mathbf{a^T B a}}{\mathbf{a^T W a}}
    \text{ subject to }
    \mathbf{a^T W a} = 1 \, ,
$$

which is equivalent to the eigenvalue / eigenvector problem

$$
\mathbf W^{-1} \mathbf B \mathbf a=\lambda \mathbf a \, .
$$

In our case, where we only have two groups, only one solution exists.
This is the eigenvector $a = \mathbf v$ and its eigenvalue.
$\mathbf v$ can can be interpreted in terms of which predictors are important to discriminate between the two classes.
We can then write the scores as

$$
\mathbf Z=\mathbf X \mathbf v \, .
$$


## Tasks {-}

##### 1. Use the `lda()` function from the `MASS` package to fit an LDA on `X` with grouping `Y`. {-}

Note that the `grouping` has to be a factor variable.

<details><summary>Solution</summary>

```{r LDA}
alon_lda <- lda(x = X, grouping = Y)

# alternative: Y ~ X
```

Note the warning regarding collinearity.

</details>

##### 2. Extract $\mathbf v$ from the `lda` object. {-}

Hint: Have a look at the "Value" section of `?lda`.

<details><summary>Solution</summary>

```{r LDA-eigenvector}
V1 <- alon_lda$scaling
```

</details>

##### 3. Compute $\mathbf Z$. {-}

<details><summary>Solution</summary>

```{r LDA-scores}
Z1 <- X %*% V1
```

</details>

##### 4. Plot the scores $\mathbf Z$ against the response to see how well the LDA separates the tumour and normal tissues groups. Interpret your plot.{-}

Hint: A boxplot would be an appropriate visualization, but feel free to be creative.

<details><summary>Solution</summary>

Using `ggplot`:

```{r LDA-ggboxplot}
ggplot(data.frame(Z1, Y), aes(x = Y, y = Z1, fill = as.factor(Y))) +
  geom_boxplot() +
  scale_fill_manual(values = cols) +
  labs(x = "Y", y = "Z",
    title = "Separation of normal and tumour samples by LDA"
  ) +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
```

Alternatively, using base `R` plotting:

```{r LDA-boxplot}
par(mfrow = c(1, 1))
boxplot(
  Z1 ~ Y, col = cols, ylab = "Z",
  main = "Separation of normal and tumour samples by LDA"
)
```

__Interpretation__: The LDA can separate the tumour and normal tissue samples very well. In comparison, the first and second components of the (sparse) PCA (an unsupervised method) in the first part of this Lab did not discriminate the two groups nearly as well.

</details>

We can view
$$
\mathbf Z = \mathbf X \mathbf v
$$
as a regression of $\mathbf Z$ on $\mathbf X$ with coefficient vector $\mathbf v$. The entries of $\mathbf v$ are non-zero for all genes.
To implement a sparse LDA, where some of the entries of $\mathbf v$ are set to zero, we can introduce an $L_1$ penalty on $\mathbf v$ and fit a Lasso regression.
The resulting $\mathbf v$ will only be determined by a few interesting genes instead of all 2000.

##### 5. Fit a Lasso model for $\mathbf Z$ with `lambda = c(0.1, 0.01, 0.001)`. Determine the number of non-zero loadings for each choice of `lambda`. {-}

<details><summary>Solution</summary>

```{r sparse-LDA}
lda_loadings <- glmnet(X, Z1, alpha = 1, lambda = c(0.2, 0.02, 0.002))
num_loadings(lda_loadings)
```

</details>

##### 6. Plot the resulting sparse scores against the response. Are the smaller subsets of genes as effective in separating the tumour and normal tissue groups as the entire set of genes? {-}

You may reuse the code from task 4 to produce 3 new plots, one for each choice of $\lambda$. Compare this to the plot for the original LDA from task 4 and interpret.

<details><summary>Solution</summary>

Using base `R` plotting:

```{r sparse-LDA-plots, fig.width = 9}
# Helper function for scatterplot between two sparse PCs
plot_sparse_LDA <- function(loadings) {
  n_nonzero <- sum(loadings[-1] != 0)
  SLDA <- X %*% loadings[-1]

  boxplot(
    SLDA ~ Y, col = cols, ylab = "Z",
    main = sprintf("Subset of %d genes", n_nonzero),
    ylim = c(-4, 4)
  )
}

par(mfrow = c(2, 2))
boxplot(
  Z1 ~ Y, col = cols, ylab = "Z",
  main = "Entire set of 2000 genes",
  ylim = c(-4, 4)
)
plot_sparse_LDA(
  as.vector(coef(lda_loadings, s = 0.002))
)
plot_sparse_LDA(
  as.vector(coef(lda_loadings, s = 0.02))
)
plot_sparse_LDA(
  as.vector(coef(lda_loadings, s = 0.2))
)
```

Alternatively, using `ggplot`:

```{r sparse-LDA-ggplots}
# Helper function for scatterplot between two sparse PCs
plot_sparse_LDA <- function(loadings) {
  n_nonzero <- sum(loadings[-1] != 0)
  SLDA <- X %*% loadings[-1]

  ggplot(data.frame(SLDA, Y), aes(x = Y, y = SLDA, fill = as.factor(Y))) +
    geom_boxplot() +
    scale_fill_manual(values = cols) +
    labs(x = "Y", y = "Z",
      title = sprintf("Subset of %d genes", n_nonzero)
    ) +
    ylim(-4, 4) +
    theme_minimal() +
    theme(legend.position = "none", plot.title = element_text(hjust = 0.5))  
}

plot1 <- ggplot(data.frame(Z1, Y), aes(x = Y, y = Z1, fill = as.factor(Y))) +
  geom_boxplot() +
  scale_fill_manual(values = cols) +
  labs(x = "Y", y = "Z",
    title = "Entire set of 2000 genes"
  ) +
  ylim(-4, 4) +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
plot2 <- plot_sparse_LDA(
  as.vector(coef(lda_loadings, s = 0.002))
)
plot3 <- plot_sparse_LDA(
  as.vector(coef(lda_loadings, s = 0.02))
)
plot4 <- plot_sparse_LDA(
  as.vector(coef(lda_loadings, s = 0.2))
)

ggarrange(plot1, plot2, plot3, plot4)
```

__Conclusion:__ Sparse LDA performs almost identically to the original LDA in separating normal and tumour tissues. Even with only the 18 most important genes, the sparse LDA is mostly able to discriminate the two classes well.
Therefore, the separation between normal and tumour tissues is mainly driven by only a small proportion of genes.

</details>

## Bonus: Evaluation of LDA as a predictive classifier {-}

We use 10-fold cross-validation to evaluate the predictive accuracy of classifications from the original LDA on all 2000 genes and the SLDA on the three smaller subsets of genes.

```{r LDA-CV}
set.seed(914751)

# Helper function to compute accuracy given v, X, and Y
lda_accuracy <- function(v, X, Y) {
  preds <- (X %*% v) > 0
  obs <- Y == "t"
  return(1 - mean(abs(preds - obs)))
}

acc_full <- acc_small <- acc_smaller <- acc_smallest <- NULL

# Randomly split the data into k folds
folds <- sample(rep(1:10, length.out = length(Y)))

for (k in 1:10) {
  # Assign the train and validation set for this fold
  val_idx <- which(folds == k)
  train_idx <- setdiff(seq_len(length(Y)), val_idx)
  X_train <- X[train_idx, , drop = FALSE]
  Y_train <- Y[train_idx]
  X_val <- X[val_idx, , drop = FALSE]
  Y_val <- Y[val_idx]

  # Fit the LDA
  lda_fold <- lda(x = X_train, grouping = Y_train)
  # Fit the SLDA with three levels of sparsity
  Z_fold <- X_train %*% lda_fold$scaling
  lasso_fold <- glmnet(X_train, Z_fold, alpha = 1, lambda = c(0.2, 0.02, 0.002))
  # Evaluate the accuracy of all four models on the validation set
  acc_full <- c(acc_full, lda_accuracy(lda_fold$scaling, X_val, Y_val))
  acc_small <- c(
    acc_small,
    lda_accuracy(as.vector(coef(lasso_fold, s = 0.002))[-1], X_val, Y_val)
  )
  acc_smaller <- c(
    acc_smaller,
    lda_accuracy(as.vector(coef(lasso_fold, s = 0.02))[-1], X_val, Y_val)
  )
  acc_smallest <- c(
    acc_smallest,
    lda_accuracy(as.vector(coef(lasso_fold, s = 0.2))[-1], X_val, Y_val)
  )
}

data.frame(
  LDA = c("original", "sparse", "sparser", "sparsest"),
  accuracy = c(
    mean(acc_full), mean(acc_small), mean(acc_smaller), mean(acc_smallest)
  )
)
```

# Additional resources {-}
- Section 4.3 (LDA) and 14.5.5 (SPCA) of @esl-book
- For a simple explanation of the concept and interpretation of LDA (and other statistical methods), have a look at <https://www.youtube.com/watch?v=azXCzI57Yfc>

```{r, child="_session-info.Rmd"}
```

# References {-}
</div>
<div class="footer">
    <hr>
    This work is licensed under the <a href= "https://creativecommons.org/licenses/by-nc-sa/4.0">
    CC BY-NC-SA 4.0</a> licence.
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("Lab4-Sparse-PCA-LDA.Rmd");
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>


</body>
</html>
